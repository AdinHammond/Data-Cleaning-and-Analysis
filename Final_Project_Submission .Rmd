---
title: "Final_Project_Submission"
author: "Adin Hammond"
date: "2023-12-08"
output: pdf_document
---

```{r Library Packages, include=FALSE}
#Library Packages
library(data.table)
library(dplyr)
library(lubridate)
library(ggplot2)
library(stringdist)
library(zipcodeR)
library(Hmisc)
library(tinytex)


```



```{r Downloading the Data, include=FALSE}
#Downloading the Data
setwd("/Users/cookiebearco/Downloads/ECON 370/Final Project /hcris_raw")
if(file.exists("rpt1998.csv")){
  
} else{
  for(i in 1998:2010){
    download.file(paste0("http://www.nber.org/hcris/265-94/rnl_rpt265_94_",i, ".csv"),
                  destfile = paste0("rpt",i,".csv"))
    download.file(paste0("http://www.nber.org/hcris/265-94/rnl_nmrc265_94_",i, "_long.csv"),
                  destfile = paste0("nmrc",i,".csv"))
    download.file(paste0("http://www.nber.org/hcris/265-94/rnl_alpha265_94_",i, "_long.csv"),
                  destfile = paste0("alpha",i,".csv"))
    
  }
}
# We used a loop to download the raw data from the websites.
```



```{r Reformatting the Raw data, include=FALSE}
#Reformatting the Raw Data

codes_non_ownership = fread("~/Downloads/codes_non_ownership.csv")
#Read in code_non_ownership

codes_non_ownership[,line := stringr::str_pad(line,5,"left","0")]
#This is getting rid of the extra zeros in the variable line 

codes_non_ownership[,column := stringr::str_pad(column,4,"left","0")]
#This is getting rid of the extra zeros in the variable column 

codes_non_ownership[,variable_key := paste0(worksheet,line,column)]
# Creating a new column named variable key. This will include the values
#in columns  worksheet, line, column

codes_non_ownership = codes_non_ownership[,.(variable,variable_key)]
# Getting ride of the worksheet, line, and column variables and keeping the 
#variable name and and variable_key columns 

```


```{r loop, include=FALSE}

#Reformatting the Raw Data

for (i in 1998:2010) {
  
  setwd("/Users/cookiebearco/Downloads/ECON 370/Final Project /hcris_raw")
  
  nmrc_temp  = fread(paste0("nmrc",i,".csv"))
  alpha_temp = fread(paste0("alpha",i,".csv"))
  rpt_temp = fread(paste0("rpt", i, ".csv"))
  #This is reading in the data for the ith year
  
  rpt_temp = rpt_temp[,.(rpt_rec_num, fy_bgn_dt, fy_end_dt) ]
  #This is keeping the only the variable columns we need in the rpt data.
  
  nmrc_temp[,line_num := stringr::str_pad(line_num,5,"left","0")]
  nmrc_temp[,clmn_num := stringr::str_pad(clmn_num,4,"left","0")]
  nmrc_temp[,variable_key := paste0(wksht_cd,line_num,clmn_num)]
  # Getting rid of extra zeros in the line and column variables, then pasting 
  #them together in a new column named variable_key
  
  nmrc_temp=merge(
    nmrc_temp,codes_non_ownership,    
    by = "variable_key"
  )
  #Merging the nmrc and codes_non_owndershio datasets by the variable_key
  
  nmrc_temp = nmrc_temp[,.(rpt_rec_num,variable,itm_val_num)]
  #This keeps only the columns in nmrc that we need
  
  nmrc_temp = dcast(nmrc_temp, rpt_rec_num ~ variable, value.var = "itm_val_num" )
  #We are making this long data wide data with variables as columns and itm_val_num
  # as the values filling up the rows
  
  alpha_temp[,line_num := stringr::str_pad(line_num,5,"left","0")]
  alpha_temp[,clmn_num := stringr::str_pad(clmn_num,4,"left","0")]
  alpha_temp[,variable_key := paste0(wksht_cd,line_num,clmn_num)]
  # Getting rid of extra zeros in the line and column variables, then pasting 
  #them together in a new column named variable_key
  
  
  alpha_temp=merge(
    alpha_temp,codes_non_ownership,    
    by = "variable_key"
  )
  #Merging the alpha and codes_non_owndershio datasets by the variable_key
  
  alpha_temp = alpha_temp[,.(rpt_rec_num,variable,alphnmrc_itm_txt)]
  # Getting rid of the columns that are uneeded. 
  
  alpha_temp = dcast(alpha_temp, rpt_rec_num ~ variable, value.var = "alphnmrc_itm_txt" )
  #We are making this long data wide data with variables as columns and alphnmrc_itm_txt
  # as the values filling up the rows
  
  alpha_temp = merge(alpha_temp,rpt_temp, by = "rpt_rec_num", all.x = T )
  #Merging the alpha and rpt data by the variable_key
  
  setwd("/Users/cookiebearco/Downloads/ECON 370/Final Project /hcris_cleaned")
  fwrite(alpha_temp,paste0("hcris",i,".csv"))
  #putting all these files in a folder "hcris_cleaned" and naming them
  
  
  if(i==1998){
    hcris_panel = merge(nmrc_temp, alpha_temp, by = "rpt_rec_num",all=T)
    hcris_panel[,year:=i]
  }else{
    hcris_temp = merge(nmrc_temp, alpha_temp, by = "rpt_rec_num",all=T)
    hcris_temp[,year:=i]
    # This code is saying that if the i=1998 then merge the nmrc and alpha and 
    #create a column "year". Name the panel hcris_panel
    
    #But if it is any other year, do the same and call it hcris_temp. 
    
    hcris_panel= rbind(hcris_panel,hcris_temp, fill = T )
    #Append it to hcris_panel.Each year is then appended sequentially to hcris_panel
  }
}
 

```





```{r Cleaning Reformatted Data, include=FALSE}

#1. 
hcris_panel = hcris_panel[!is.na(hcris_panel$prvdr_num), ]
#Keeping the provider numbers that are nor missing 
hcris_panel[,prvdr_num:=as.numeric(prvdr_num)]
#Making all the provider numbers numeric instead of vector


#2. 

hcris_panel$epo_net = abs(hcris_panel$epo_cost)
hcris_panel$epo_net_cost = abs(hcris_panel$epo_net_cost)
hcris_panel$epo_rebates = abs(hcris_panel$epo_rebates)
#Taking the absolute value of the  variables epo_cost, epo_net_cost, and epo_rebates

#3. 
hcris_panel$epo_rebates[is.na(hcris_panel$epo_rebates)]= 0
 #if the epo_rebates are missing, then fill them with 0

#4. 
#(a)
hcris_panel[is.na(epo_cost) & !is.na(epo_net_cost) & epo_rebates== 0, epo_cost := epo_net_cost]
#Where epo_cost is missing, epo_net_cost is not missing, and epo_rebates is equal to zero, make epo_cost = epo_net_cost.
#(b)
hcris_panel[is.na(epo_cost) & !is.na(epo_net_cost) & epo_rebates!=0, epo_cost:=epo_rebates]
#Where epo_cost is missing, epo_net_cost is not missing, and epo_rebates does not equal zero, make epo_cost = epo_rebates.
#(c)
hcris_panel[is.na(epo_cost) & is.na(epo_net_cost) & epo_rebates== 0, `:=`(epo_cost=0,epo_net_cost=0)]
#Where epo_cost is missing, epo_net_cost is missing, and epo_rebates equals zero, make epo_cost = 0 and epo_net_cost=0 at the same time.
#(e)
hcris_panel[!is.na(epo_cost) & is.na(epo_net_cost), epo_net_cost:= epo_cost - epo_rebates]
#Where epo_cost is not missing, epo_net_cost is missing, make epo_net_cost = epo_cost - epo_rebates

#5
hcris_panel[epo_cost<epo_net_cost, ':='(epo_cost=epo_net_cost, epo_net_cost = epo_cost)]
#Where epo_cost is less than epo_net_cost, make epo_cost equal to epo_net_cost and make epo_net_cost equal to epo_cost at the same time.

#6
hcris_panel[prvdr_num==322664, prvdr_num:= 342664]
# When provider number is equal to 322664 change it to 342664

#7
mdy(hcris_panel$fy_bgn_dt)
mdy(hcris_panel$fy_end_dt)
mdy(hcris_panel$report_start_date)
mdy(hcris_panel$report_end_date)
# Used lubridate to made the fiscal year beginning and end data and report start and end date uniform

#8
hcris_panel[,report_start_date := NULL]
hcris_panel[,report_end_date := NULL]
# We got rid of the report start and end data columns 

#9
#(a)
hcris_panel[, zip_code := trimws(zip_code)]
hcris_panel[, zip_code := substr(zip_code,1,5)]
#We trimmed the zipcode to get rid of spaces.
#Then we used substr() to keep only the 1-5 values.

#(b)

hcris_panel[ , Nzip := length(unique(zip_code[!is.na(zip_code)])), by= prvdr_num]
hcris_panel[Nzip == 1, zip_code := unique(zip_code[!is.na(zip_code)]), by = prvdr_num] 
sum(is.na(hcris_panel$zip_code))
# We made an additional column named Nzip that counted the number of unique zipcodes there were. 
# Then where Nzip was == 1 (no including Nas), we assigned that unique zip code 
#to missing values with the same provider number
#We then used the third line of code to check if ther were less missing zipcodes.

#(c)
# But if there are multiple unique values then use the modal zip code to fill in the NAs
mode = function(x){
  uniqx = unique(x[!is.na(x)])
  uniqx[which.max(tabulate(match(x,uniqx)))]
}
hcris_panel[ Nzip > 1, zip_code:= mode(zip_code), by= prvdr_num]
#If Nzip was greater than 1, then we found the most common zip code for that provider number 
#We then assigned the missing zipcodes by provider number to the modal zipcode.

#10
hcris_panel[ Nzip!=0 ,state := reverse_zipcode(zip_code[!is.na(zip_code)])$state, by = prvdr_num]
# When Nzip did not equal zero, we used the reverse zipcode function to fill in the 
#states with the corresponding zipcode(non missing zipcodes) , by provider number.

#11
hcris_panel[, sort(unique(hcris_panel$chain_identity))]
hcris_panel[grepl("^FRE", chain_identity), chain_identity := "FRESENIUS" ]
hcris_panel[grepl("^FER", chain_identity), chain_identity := "FRESENIUS" ]
hcris_panel[grepl("^FES", chain_identity), chain_identity := "FRESENIUS" ]
hcris_panel[grepl("^FEN", chain_identity), chain_identity := "FRESENIUS" ]
hcris_panel[grepl("^FRS", chain_identity), chain_identity := "FRESENIUS" ]
hcris_panel[grepl("^FR4", chain_identity), chain_identity := "FRESENIUS" ]
hcris_panel[grepl("^FRR", chain_identity), chain_identity := "FRESENIUS" ]

hcris_panel[grepl("^DAV", chain_identity), chain_identity := "DAVITA" ]
hcris_panel[grepl("^DAT", chain_identity), chain_identity := "DAVITA" ]
hcris_panel[grepl("^DAN", chain_identity), chain_identity := "DAVITA" ]
hcris_panel[grepl("^DAC", chain_identity), chain_identity := "DAVITA" ]
# This is how we accounted for misspellings in Fresenius and Davita. 


hcris_panel[is.na(chain_indicator), chain_indicator := "N"]
# If the chain indicator was missing we assigned  it "N'
hcris_panel[chain_indicator == "N" , chain_id := 0 ]
#If the chain indicator was "N", than we made a new column and assigned filled in zeros
hcris_panel[chain_indicator == "Y" & chain_identity != c("DAVITA", "FRESENIUS" ) , chain_id := 1]
#If the chain indicator was "Y" and the Chain identity was not Davita or Fresenius, then we made the chain id 1
hcris_panel[chain_id == 0, chain_identity := "Independent"]
#If the chain id was zero then we made the chain identity "Independent"
hcris_panel[chain_id == 1 , chain_identity :=  "Other"]
#If the chain id was was hen we made the chain identity "Other"
hcris_panel[chain_identity == "FRESENIUS", chain_id := 3 ]
#If the chain identity was "Fresenius" then we made the chain id = 3
hcris_panel[chain_identity == "DAVITA", chain_id := 2 ]
#If the chain identity was was Davita then we made the chain id = 2

#12

hcris_panel[, chain_indicator := chain_identity]
#We made chain indicator the same as chain identity
hcris_panel[, chain_indicator:= NULL ]
#We deleted the chain idicator colums 
clean = hcris_panel
Cleaned_data = hcris_panel
#I added new names for the hcris_panel so that future code would call the same data.
```


Note: Only the Analysis is included in the Rmarkdown

##Analysis 1: Do chains change their dialyzers more often or less often than independents

```{r Analysis1, echo=FALSE}
#Analysis: Do chains change their dialyzers more often or less often than independents

### So NIndep is a variable that is just the non-independent values of clean
### Indep is just the independent ones
NIndep = clean[clean$chain_identity != "Independent"]
Indep =  clean[clean$chain_identity == "Independent"]

inre = Indep$dialyser_reuse_times
ninre =NIndep$dialyser_reuse_times
### inre is the indepedent reuse times for the dialyser
### ninre is the non-idependent reuse times for the dialyser
inre2 <- na.omit(inre)
summary(inre2)
IQR =  (quantile(inre2, 0.75)-quantile(inre2, 0.25)) ###
outlier_test =  IQR*1.5
upperbound = quantile(inre2, 0.75) + outlier_test
lowerbound = quantile(inre2, 0.25) - outlier_test
### since the min is higher than the lower bound we dont have to do anything checking those boundaries.
inre_noout = inre2[inre2 <= upperbound]
mean(inre_noout)

ninre2 <- na.omit(ninre)
summary(ninre2)
IQR2 =  (quantile(ninre2, 0.75)-quantile(ninre2, 0.25))
upperbound2 = quantile(ninre2, 0.75) + outlier_test
lowerbound2 = quantile(ninre2, 0.25) - outlier_test
ninre_noout = ninre2[ninre2 <= upperbound]


ggplot(data.frame(x = inre_noout), aes(x)) + geom_density(fill = "blue", alpha = 0.5) + labs(title = " Independents Density Plot", x = "Dialyzer Reuses", y = "Density")
ggplot(data.frame(x = ninre_noout), aes(x)) + geom_density(fill = "green", alpha = 0.5) + labs(title = " Chain Density Plot", x = " Dialyzers Reuses", y = "Density")
#hist(inre_noout)
#hist(ninre_noout)
```


```{r Analysis2, echo=F}

# Plotting
plot(density(inre_noout), col = "blue",  main = "Overlaying Density Plots", xlim = c(min(inre_noout, ninre_noout), max(inre_noout, ninre_noout)), xlab = "Dialyzers Reuses", ylab = "Density")
lines(density(ninre_noout), col = "red")


# Add legend
legend("topright", legend = c("Independents", "Chains"), fill = c("blue", "red"))


 
```
Summary: We found that Independents and Chains reuse dialyzers about the same amount for low and higher levels of reuses. However around 10 reuses, Independents reuse more frequently. 





##Analysis 2: Do chains use more epo than independents 

```{r Anaysis4, echo=FALSE}
# Do chains use more epo than independents 
clean$total_machines=clean$num_machines_regular+clean$num_machines_standby
clean_vector=clean$num_machines_regular+clean$num_machines_standby
clean_vector=na.omit(clean_vector)

bins=cut2(clean_vector, g=5)
table(bins)

clean=clean %>%
  mutate(bins = case_when(
    total_machines >= 2 & total_machines < 15  ~ 'bin 1',
    total_machines >= 15 & total_machines < 19 ~ 'bin 2',
    total_machines >= 19 & total_machines < 23 ~ 'bin 3',
    total_machines >= 23 & total_machines < 28 ~ 'bin 4',
    total_machines >= 28 ~ 'bin 5',
    TRUE ~ 'other'  
  ))

```






```{r echo=FALSE}

clean_chain=clean[clean$chain_identity != 'Independent', ]
clean_ind=clean[clean$chain_identity == 'Independent', ]

calculate_summary_by_bin=function(df, bin_name) {
  df %>%
    filter(bins == bin_name) %>%
    summarise(
      count = n(),
      mean_epo_net_cost = mean(epo_net_cost, na.rm = TRUE),
      median_epo_net_cost = median(epo_net_cost, na.rm = TRUE),
      sd_epo_net_cost = sd(epo_net_cost, na.rm = TRUE),
      min_epo_net_cost = min(epo_net_cost, na.rm = TRUE),
      max_epo_net_cost = max(epo_net_cost, na.rm = TRUE)
    ) %>%
    mutate(bin = bin_name) 
}

bins_list=paste("bin", 1:5)

summary_chain_by_bin=lapply(bins_list, calculate_summary_by_bin, df = clean_chain) %>%
  bind_rows()

summary_ind_by_bin=lapply(bins_list, calculate_summary_by_bin, df = clean_ind) %>%
  bind_rows()

summary_combined=bind_rows(
  mutate(summary_chain_by_bin, chain_type = "Chain"),
  mutate(summary_ind_by_bin, chain_type = "Independent")
)

bin_ranges=c("2-14", "15-18", "19-22", "23-27", "28+")
summary_combined$bin=factor(summary_combined$bin, 
                               levels = paste("bin", 1:5),
                               labels = bin_ranges)

ggplot(summary_combined, aes(x = bin, y = mean_epo_net_cost, fill = chain_type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Mean EPO Net Cost by Bin",
       x = "Bin Range (total_machines)",
       y = "Mean EPO Net Cost",
       fill = "Chain Type") +
  scale_x_discrete(labels = bin_ranges) + # Set the labels on the x-axis
  theme_minimal()
```
Our objective was to compare the EPO costs that were associated with both chains and independents across similar numbers of patients. We found that the total number of machines, calculated by adding regular machines with standby machines, would be an appropriate approximation to the patient capacity of the clinics. 

We concluded that the EPO costs were very dependent on the total number of machines available in the clinic. For clinics with a total number of machines that were smaller, or less than 18, the mean EPO cost was higher for chains. However, if we increase the total number of machines above 18, the mean EPO costs become higher for independents. 









##Analysis 3: How busy are clinics as a whole throughout the years. 


For our next analysis question, we are interested in determining how busy the clinics tend to be as a whole. We are interested in this data because it will be useful in determining how the demand for dialysis has chnaged over the years.




```{r echo=FALSE}
yearly_avg=aggregate(avg_weekly_sessions ~ year, clean, mean, na.rm = TRUE)

ggplot(yearly_avg, aes(x = year, y = avg_weekly_sessions)) +
  geom_line() +
  ggtitle("Average Weekly Sessions per Year") +
  xlab("Year") +
  ylab("Average Weekly Sessions")

```




The graph depicts fluctuations in the average weekly sessions per year, with a notable decline in the late 1990s, a sharp peak in the early 2000s followed by a significant dip, and a subsequent recovery by the early 2010s. 

These variations could be attributed to a range of factors including regulatory changes affecting healthcare practices, economic conditions influencing patient attendance, technological advancements in medicine, demographic shifts in the patient population, or specific events impacting healthcare demand.

The peak and decline in the mid-2000s could suggest a temporary policy change or health crisis. To understand these trends comprehensively, one would need to investigate the historical context concerning healthcare policies, economic data, technological developments, demographic information, and notable events during the years of significant change.



